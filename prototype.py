import streamlit as st
import numpy as np
import cv2
from PIL import Image
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import tempfile
import os
import torch

# --- MODEL LOADING ---
@st.cache_resource
def load_text_model():
    """Loads a text detection model specifically designed for AI-generated text detection"""
    try:
        # Using a model specifically designed for AI-generated text detection
        return pipeline("text-classification", 
                       model="roberta-base-openai-detector",
                       tokenizer="roberta-base")
    except Exception as e:
        st.error(f"FATAL: Could not load the text detection model. Error: {e}")
        st.stop()

@st.cache_resource
def load_deepfake_model():
    """Loads a deepfake detection model (image-based)."""
    try:
        return pipeline("image-classification", model="umm-maybe/AI-image-detector")
    except Exception as e:
        st.error(f"Error loading deepfake detection model: {e}")
        return None

# Load the models
text_detector = load_text_model()
image_detector = load_deepfake_model()

# --- HELPER FUNCTIONS ---

def analyze_text(text):
    """
    Analyze text for AI-generated content using a specialized model
    """
    if not text.strip():
        return None
        
    # Ensure text has sufficient length for analysis
    if len(text.split()) < 10:
        st.warning("For best results, please provide at least 10-15 words of text.")
        return None
        
    try:
        # Get prediction from the model
        result = text_detector(text, truncation=True, max_length=512)[0]
        
        # The model returns either 'Fake' (AI-generated) or 'Real' (human-written)
        if result['label'] == 'Fake':
            ai_score = result['score']
        else:
            ai_score = 1 - result['score']
            
        return ai_score

    except Exception as e:
        st.error(f"An error occurred during text analysis: {e}")
        return None

def analyze_video(video_file):
    """
    *YOUR PREFERRED VERSION:* Analyzes video with the hyper-sensitive, fixed-threshold logic.
    This code is exactly as you provided it in the last prompt.
    """
    if video_file is None: return None
    video_path = ""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
            tfile.write(video_file.read())
            video_path = tfile.name
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            st.error("Error: Could not open video file.")
            return None
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        frame_count, fake_count, face_frames = 0, 0, 0
        max_frames_to_process = 100
        progress_bar = st.progress(0, text="Analyzing video frames...")
        while cap.isOpened() and frame_count < max_frames_to_process:
            ret, frame = cap.read()
            if not ret: break
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray_frame, 1.1, 4)
            if len(faces) > 0:
                face_frames += 1
                (x, y, w, h) = faces[0]
                face_roi = frame[y:y+h, x:x+w]
                face_image = Image.fromarray(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))
                result = image_detector(face_image)
                if any(d['label'].lower() == 'artificial' and d['score'] > 0.75 for d in result):
                    fake_count += 1
            frame_count += 1
            progress_bar.progress(frame_count / max_frames_to_process, text=f"Analyzing video frames... ({frame_count}/{max_frames_to_process})")
        cap.release()
        progress_bar.empty()
        if face_frames == 0:
            return {"message": "No faces were detected in the processed video segment."}
        return {"faces_detected_in_frames": face_frames, "frames_classified_as_fake": fake_count}
    finally:
        if video_path and os.path.exists(video_path):
            os.remove(video_path)


# --- STREAMLIT UI ---

st.set_page_config(page_title="Fake Guard", page_icon="ðŸ›¡", layout="wide")
st.title("ðŸ›¡ Fake Guard: AI-Generated Content Detector")
st.markdown("---")

st.sidebar.title("Navigation")
detection_mode = st.sidebar.radio("Choose a detection mode:", ("Text Detection", "Video Detection"))

if detection_mode == "Text Detection":
    st.header("AI-Generated Text Detection")
    st.info("This tool analyzes text to detect if it was generated by AI. For best results, provide at least a paragraph of text.")

    input_text = st.text_area("Enter text here:", height=250, placeholder="Paste a paragraph, an email, or any text you want to check...")
    
    if st.button("Analyze Text"):
        if text_detector is None:
            st.error("Text detection model is unavailable.")
        elif input_text:
            with st.spinner("Analyzing text content..."):
                ai_score = analyze_text(input_text)
                if ai_score is not None:
                    st.subheader("Analysis Results")
                    
                    # Display the AI score
                    st.metric(label="AI-Generated Likelihood", value=f"{ai_score:.2%}")
                    st.progress(ai_score)

                    # Provide a simple verdict based on the score
                    if ai_score > 0.75:
                        st.error("*Verdict:* This text is very likely AI-generated.")
                    elif ai_score > 0.45:
                        st.warning("*Verdict:* This text shows some characteristics of AI-generation.")
                    elif ai_score > 0.25:
                        st.info("*Verdict:* This text is likely human-written with possible AI assistance.")
                    else:
                        st.success("*Verdict:* This text is likely Human-written.")

        else:
            st.warning("Please enter some text to analyze.")

elif detection_mode == "Video Detection":
    # *YOUR PREFERRED UI:* This is the exact UI code you provided.
    st.header("Deepfake Video Detection")
    st.write("This tool analyzes video frames for signs of AI generation.")
    st.warning("An authentic video should have *zero* suspicious frames. The detection of even one AI-generated frame is a strong indicator of manipulation.", icon="âš ")
    uploaded_video = st.file_uploader("Choose a video file...", type=["mp4", "mov", "avi"])
    if st.button("Analyze Video"):
        if image_detector is None:
            st.error("Video detection model is not available.")
        elif uploaded_video:
            result = analyze_video(uploaded_video)
            if result:
                if "message" in result:
                    st.info(result['message'])
                else:
                    frames_with_faces = result['faces_detected_in_frames']
                    fake_frames = result['frames_classified_as_fake']
                    col1, col2 = st.columns(2)
                    col1.metric("Frames with Faces Detected", f"{frames_with_faces}")
                    col2.metric("Suspicious Frames Flagged", f"{fake_frames}")
                    if fake_frames > 1:
                        st.error(f"*High Suspicion:* {fake_frames} frames were flagged as potentially AI-generated. This is a strong indicator of a deepfake or manipulated video.")
                    elif fake_frames == 1:
                        st.warning(f"*Moderate Suspicion:* 1 frame was flagged as potentially AI-generated. This is unusual and warrants careful review.")
                    else:
                        st.success("*Low Suspicion:* No frames were flagged as AI-generated. The video appears to be authentic.")
        else:
            st.warning("Please upload a video file to analyze.")

st.markdown("---")
st.markdown("Built with guidance from a Large Language Model. Uses open-source models and tools.")